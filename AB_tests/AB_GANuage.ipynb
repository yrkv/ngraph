{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from NeuralGraph import NeuralGraph\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    }
   ],
   "source": [
    "# One listener node\n",
    "# n_random random nodes\n",
    "# brain_size brain nodes\n",
    "# One speaker node\n",
    "\n",
    "n_random = 1\n",
    "brain_size = 16\n",
    "emb_dim = 64\n",
    "T = 3\n",
    "\n",
    "listener_node = np.arange(0, 1)\n",
    "random_nodes = np.arange(1, n_random+1)\n",
    "brain_nodes = np.arange(1+n_random, 1+n_random+brain_size)\n",
    "speaker_node = np.arange(1+n_random+brain_size, 2+n_random+brain_size)\n",
    "\n",
    "connections = [(i, j) for nodes1, nodes2 in [(listener_node, brain_nodes), (random_nodes, brain_nodes), (brain_nodes, brain_nodes), (brain_nodes, speaker_node)] for i in nodes1 for j in nodes2]\n",
    "\n",
    "print(len(connections))\n",
    "\n",
    "gen_graph = NeuralGraph(brain_size+n_random+2, 1+n_random, 1, connections, ch_n=32, ch_e=32, ch_k=32, ch_inp=emb_dim, ch_out=emb_dim, device=device)\n",
    "\n",
    "def generate(x, n_tokens=16):\n",
    "    # x should be of shape (bs, seqlen, emb_dim)\n",
    "    assert len(x.shape) == 3 and x.shape[-1] == emb_dim\n",
    "    \n",
    "    # Append noise\n",
    "    x = torch.cat([x.unsqueeze(-2), torch.rand(x.shape[0], x.shape[1], n_random, x.shape[2])], axis=-2)\n",
    "    gen_graph.init_vals(batch_size=x.shape[0])\n",
    "\n",
    "    for token in range(x.shape[1]):\n",
    "        gen_graph.apply_vals(x[:, token])\n",
    "        for t in range(T):\n",
    "            gen_graph.timestep(t=t)\n",
    "\n",
    "    outputs = []\n",
    "    for _ in range(n_tokens-1):\n",
    "        outputs.append(gen_graph.read_outputs())\n",
    "        for t in range(T):\n",
    "            gen_graph.timestep()    \n",
    "    outputs.append(gen_graph.read_outputs())\n",
    "\n",
    "    outputs = torch.stack(outputs, axis=1)\n",
    "\n",
    "    return outputs.squeeze(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n"
     ]
    }
   ],
   "source": [
    "listener_node = np.arange(0, 1)\n",
    "brain_nodes = np.arange(1, 1+brain_size)\n",
    "guesser_node = np.arange(1+brain_size, 2+brain_size)\n",
    "\n",
    "connections = [(i, j) for nodes1, nodes2 in [(listener_node, brain_nodes), (brain_nodes, brain_nodes), (brain_nodes, guesser_node)] for i in nodes1 for j in nodes2]\n",
    "\n",
    "print(len(connections))\n",
    "\n",
    "critic_graph = NeuralGraph(brain_size+2, 1, 1, connections, ch_n=32, ch_e=32, ch_k=32, ch_inp=emb_dim, ch_out=1, device=device)\n",
    "\n",
    "def score(x):\n",
    "    # x should be of shape (bs, seqlen, emb_dim)\n",
    "    assert len(x.shape) == 3 and x.shape[-1] == emb_dim\n",
    "\n",
    "    critic_graph.init_vals(batch_size=x.shape[0])\n",
    "\n",
    "    for token in range(x.shape[1]):\n",
    "        critic_graph.apply_vals(x[:, token].unsqueeze(-2))\n",
    "        for t in range(T):\n",
    "            critic_graph.timestep(t=t)\n",
    "\n",
    "    return critic_graph.read_outputs().squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 64])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "inps = torch.randn(4, 8, emb_dim)\n",
    "fake = generate(inps)\n",
    "print(fake.shape)\n",
    "scores = score(fake)\n",
    "print(scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "eval_batch_size = 16\n",
    "\n",
    "\n",
    "\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "def data_process(raw_text_iter: dataset.IterableDataset):\n",
    "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "# ``train_iter`` was \"consumed\" by the process of building the vocab,\n",
    "# so we have to create it again\n",
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def batchify(data, bsz: int):\n",
    "    \"\"\"Divides the data into ``bsz`` separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "\n",
    "    Arguments:\n",
    "        data: Tensor, shape ``[N]``\n",
    "        bsz: int, batch size\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape ``[N // bsz, bsz]``\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "train_data = batchify(train_data, batch_size)  # shape ``[seq_len, batch_size]``\n",
    "val_data = batchify(val_data, eval_batch_size)\n",
    "test_data = batchify(test_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 16\n",
    "def get_batch(source, i: int):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape ``[full_seq_len, batch_size]``\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape ``[seq_len, batch_size]`` and\n",
    "        target has shape ``[seq_len * batch_size]``\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+seq_len:i+2*seq_len]# .reshape(-1)\n",
    "    return torch.swapaxes(data, 0, 1), torch.swapaxes(target, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16]) torch.Size([16, 16])\n",
      "torch.Size([16, 16, 64]) torch.Size([16, 16, 64])\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(train_data, 0)\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "embedder = nn.Embedding(len(vocab), emb_dim)\n",
    "\n",
    "emb_x, emb_y = embedder(x), embedder(y)\n",
    "\n",
    "print(emb_x.shape, emb_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_opt = torch.optim.Adam(gen_graph.parameters(), lr=1e-4)\n",
    "crit_opt = torch.optim.Adam(critic_graph.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gp(real, fake):\n",
    "\n",
    "    eps = torch.rand(batch_size, 1, 1).to(device)\n",
    "    eps = eps.expand_as(real)\n",
    "    interpolation = eps * real + (1 - eps) * fake\n",
    "\n",
    "    # print(interpolation.shape)\n",
    "    interp_logits = score(interpolation)\n",
    "    grad_outputs = torch.ones_like(interp_logits)\n",
    "\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=interp_logits,\n",
    "        inputs=interpolation,\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    grad_norm = gradients.norm(2, 1)\n",
    "    return torch.mean((grad_norm - 1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen loss : -39.18990 | Crit loss : 0.99485\n"
     ]
    }
   ],
   "source": [
    "for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt*2)):\n",
    "    inp, real = get_batch(train_data, i)\n",
    "    emb_inp = embedder(inp)\n",
    "    emb_real = embedder(real)\n",
    "\n",
    "    # Gen update\n",
    "\n",
    "    # gen_graph.train()\n",
    "    # critic_graph.eval()\n",
    "\n",
    "    # gen_opt.zero_grad()\n",
    "    # fake = generate(emb_inp, n_tokens=bptt)\n",
    "    # fake_scores = score(torch.cat([emb_inp, fake], axis=1))\n",
    "    # gen_loss = -fake_scores.mean()\n",
    "    # gen_loss.backward()\n",
    "    # gen_opt.step()\n",
    "\n",
    "\n",
    "    # Crit update\n",
    "    \n",
    "    gen_graph.eval()\n",
    "    critic_graph.train()\n",
    "\n",
    "    crit_opt.zero_grad()\n",
    "    fake2 = generate(emb_inp, n_tokens=bptt)\n",
    "    true_scores = score(torch.cat([emb_inp, emb_real], axis=1))\n",
    "    fake_scores = score(torch.cat([emb_inp, fake2], axis=1))\n",
    "    crit_loss = fake_scores.mean() - true_scores.mean() + compute_gp(emb_real, fake2)\n",
    "    crit_loss.backward()\n",
    "    crit_opt.step()\n",
    "\n",
    "    print(f\"Gen loss : {gen_loss.item():0.5f} | Crit loss : {crit_loss.item():0.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
